{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the needed libraries and functions\n",
    "#Import SKlearn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA #used for dimension reduction\n",
    "\n",
    "#Import Pandas and Matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "#import Models\n",
    "from sklearn import svm, tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "#import Bokeh\n",
    "from bokeh.io import output_notebook, show, push_notebook, reset_output\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.embed import components\n",
    "output_notebook()\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.palettes import Spectral6\n",
    "\n",
    "#create custom function for future usage..\n",
    "def transform_label_encoder(value):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(value)\n",
    "    return le.transform(value)\n",
    "\n",
    "def transform_to_standard_scaler(train, test):\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(train), scaler.transform(test)\n",
    "\n",
    "def transform_to_minmax_scaler(train, test):\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    return min_max_scaler.fit_transform(train), min_max_scaler.transform(test)\n",
    "\n",
    "def transform_to_pca(train, test, n=1):\n",
    "    pca = PCA(n_components=n)\n",
    "    return pca.fit_transform(train), pca.transform(test)\n",
    "\n",
    "def print_line():\n",
    "    for x in range (1, 30):  \n",
    "        print(\"-\",end=\" \")\n",
    "    print()\n",
    "\n",
    "def print_accuracy(model, X, y, model_name, data_type_set):\n",
    "    print('Accuracy of '+str(model_name)+' on '+str(data_type_set)+' set: {:.4f}'.format(model.score(X, y)))\n",
    "\n",
    "def print_model_score(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    print_accuracy(model, X_train, y_train, model_name, 'training')\n",
    "    print_accuracy(model, X_test, y_test, model_name, 'test')\n",
    "    print_line()\n",
    "\n",
    "def print_model_score_without_line(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    print_accuracy(model, X_train, y_train, model_name, 'training')\n",
    "    print_accuracy(model, X_test, y_test, model_name, 'test')   \n",
    "\n",
    "def plot_confusion_matrix(X, y, model):\n",
    "    mat = confusion_matrix(y, model.predict(X))\n",
    "    sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "    plt.xlabel('true label')\n",
    "    plt.ylabel('predicted label');\n",
    "    sns.plt.show()\n",
    "    tn, fp, fn, tp = mat.ravel()\n",
    "    print('Total True Positive and True Negative:',str(tn + tp))\n",
    "    print('Total False Positive and False Negative:',str(fp + fn))\n",
    "    print('Accurancy:',str((tn + tp) / (tn + tp + fp + fn)))\n",
    "\n",
    "def find_column_null(df):\n",
    "    return df.columns[df.isnull().any()].tolist()\n",
    "\n",
    "def calculate_model_scores(list_of_models, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    highest_train_score = 0\n",
    "    highest_train_model = ''\n",
    "    \n",
    "    highest_test_score = 0\n",
    "    highest_test_model = ''\n",
    "    \n",
    "    highest_precision_score = 0\n",
    "    highest_precision_model = ''\n",
    "    \n",
    "    for m_name, model in list_of_models:\n",
    "        #calculate y prediction\n",
    "        y_predict = model.predict(X_test)\n",
    "        \n",
    "        train_score = model.score(X_train, y_train)\n",
    "        test_score = model.score(X_test, y_test)\n",
    "        p_score = precision_score(y_test, y_predict, average='weighted')\n",
    "        \n",
    "        if(train_score > highest_train_score):\n",
    "            highest_train_score = train_score\n",
    "            highest_train_model = m_name\n",
    "        \n",
    "        if(test_score > highest_test_score):\n",
    "            highest_test_score = test_score\n",
    "            highest_test_model = m_name\n",
    "        \n",
    "        if(p_score > highest_precision_score):\n",
    "            highest_precision_score = p_score\n",
    "            highest_precision_model = m_name\n",
    "        \n",
    "        print(str(m_name) + ' Accuracy score (training set):', train_score)\n",
    "        print(str(m_name) + ' Accuracy score (test set):', test_score)\n",
    "        print(str(m_name) + ' F1 score:', f1_score(y_test, y_predict, average='weighted'))\n",
    "        print(str(m_name) + ' Recall:', recall_score(y_test, y_predict, average='weighted'))\n",
    "        print(str(m_name) + ' Precision:', p_score)\n",
    "        print(str(m_name) + ' ROC and AUC score:', roc_auc_score(y_test, y_predict))\n",
    "        print_line()\n",
    "    \n",
    "    print_line()\n",
    "    print('Highest Accuracy score (training set):', str(highest_train_model), '. Score: ', highest_train_score)\n",
    "    print('Highest Accuracy score (test set):', str(highest_test_model), '. Score: ', highest_test_score)\n",
    "    print('Highest Accuracy score (Precision):', str(highest_precision_model), '. Score: ', highest_precision_score)\n",
    "    \n",
    "#End class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dota2 Games Results Data Set \n",
    "\n",
    "Data Set Information:\n",
    "\n",
    "Dota 2 is a popular computer game with two teams of 5 players. At the start of the game each player chooses a unique hero with different strengths and weaknesses. The dataset is reasonably sparse as only 10 of 113 possible heroes are chosen in a given game. All games were played in a space of 2 hours on the 13th of August, 2016\n",
    "\n",
    "URL: https://archive.ics.uci.edu/ml/datasets/Dota2+Games+Results\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "Each row of the dataset is a single game with the following features (in the order in the vector):\n",
    "1. Team won the game (1 or -1)\n",
    "2. Cluster ID (related to location)\n",
    "3. Game mode (eg All Pick)\n",
    "4. Game type (eg. Ranked)\n",
    "5. end: Each element is an indicator for a hero. Value of 1 indicates that a player from team '1' \n",
    "played as that hero and '-1' for the other team. Hero can be selected by only one player each game. \n",
    "This means that each row has five '1' and five '-1' values.\n",
    "\n",
    "Radiant = 1, Dire = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the dataset\n",
    "train = pd.read_csv('dota2Train.csv', header=None)\n",
    "test = pd.read_csv('dota2Test.csv', header=None)\n",
    "\n",
    "columns = ['team_won', 'cluster_id', 'game_mode', 'game_type',\n",
    "           'antimage','axe','bane','bloodseeker','crystal_maiden','drow_ranger',\n",
    "           'earthshaker','juggernaut','mirana','nevermore','morphling',\n",
    "           'phantom_lancer','puck','pudge','razor','sand_king',\n",
    "           'storm_spirit','sven','tiny','vengefulspirit',\n",
    "           'windrunner','zeus','kunkka','lina','lich','lion',\n",
    "           'shadow_shaman','slardar','tidehunter','witch_doctor',\n",
    "           'riki','enigma','tinker','sniper','necrolyte','warlock',\n",
    "           'beastmaster','queenofpain','venomancer','faceless_void',\n",
    "           'skeleton_king','death_prophet','phantom_assassin','pugna',\n",
    "           'templar_assassin','viper','luna','dragon_knight','dazzle',\n",
    "           'rattletrap','leshrac','furion','life_stealer','dark_seer',\n",
    "           'clinkz','omniknight','enchantress','huskar','night_stalker',\n",
    "           'broodmother','bounty_hunter','weaver','jakiro','batrider',\n",
    "           'chen','spectre','doom_bringer','ancient_apparition','ursa',\n",
    "           'spirit_breaker','gyrocopter','alchemist','invoker','silencer',\n",
    "           'obsidian_destroyer','lycan','brewmaster','shadow_demon','lone_druid',\n",
    "           'chaos_knight','meepo','treant','ogre_magi','undying','rubick','disruptor',\n",
    "           'nyx_assassin','naga_siren','keeper_of_the_light','wisp','visage','slark',\n",
    "           'medusa','troll_warlord','centaur','magnataur','shredder','bristleback',\n",
    "           'tusk','skywrath_mage','abaddon','elder_titan','legion_commander','ember_spirit',\n",
    "           'earth_spirit','abyssal_underlord','terrorblade','phoenix','techies','oracle',\n",
    "           'winter_wyvern','arc_warden', 'unknown_hero'\n",
    "          ]\n",
    "\n",
    "train.columns = columns\n",
    "test.columns = columns\n",
    "\n",
    "train.head()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the shape of the data\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Top 6 Most pick hero\n",
    "hero_lists = ['antimage','axe','bane','bloodseeker','crystal_maiden','drow_ranger',\n",
    "           'earthshaker','juggernaut','mirana','nevermore','morphling',\n",
    "           'phantom_lancer','puck','pudge','razor','sand_king',\n",
    "           'storm_spirit','sven','tiny','vengefulspirit',\n",
    "           'windrunner','zeus','kunkka','lina','lich','lion',\n",
    "           'shadow_shaman','slardar','tidehunter','witch_doctor',\n",
    "           'riki','enigma','tinker','sniper','necrolyte','warlock',\n",
    "           'beastmaster','queenofpain','venomancer','faceless_void',\n",
    "           'skeleton_king','death_prophet','phantom_assassin','pugna',\n",
    "           'templar_assassin','viper','luna','dragon_knight','dazzle',\n",
    "           'rattletrap','leshrac','furion','life_stealer','dark_seer',\n",
    "           'clinkz','omniknight','enchantress','huskar','night_stalker',\n",
    "           'broodmother','bounty_hunter','weaver','jakiro','batrider',\n",
    "           'chen','spectre','doom_bringer','ancient_apparition','ursa',\n",
    "           'spirit_breaker','gyrocopter','alchemist','invoker','silencer',\n",
    "           'obsidian_destroyer','lycan','brewmaster','shadow_demon','lone_druid',\n",
    "           'chaos_knight','meepo','treant','ogre_magi','undying','rubick','disruptor',\n",
    "           'nyx_assassin','naga_siren','keeper_of_the_light','wisp','visage','slark',\n",
    "           'medusa','troll_warlord','centaur','magnataur','shredder','bristleback',\n",
    "           'tusk','skywrath_mage','abaddon','elder_titan','legion_commander','ember_spirit',\n",
    "           'earth_spirit','abyssal_underlord','terrorblade','phoenix','techies','oracle',\n",
    "           'winter_wyvern','arc_warden', 'unknown_hero'\n",
    "]\n",
    "\n",
    "top_6 = pd.DataFrame({'hero':hero_lists,'total_pick':0})\n",
    "top_6.total_pick = top_6.total_pick.astype(int)\n",
    "\n",
    "#for index, row in train.iterrows():\n",
    "#    for hero in hero_lists:\n",
    "#        if(row[hero] == 1 or row[hero] == -1):\n",
    "#            print(hero)\n",
    "#            mask = (top_5.hero == hero)\n",
    "#            top_5[mask].total_pick = top_5[mask].total_pick + 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hero in hero_lists:\n",
    "    total_pick = train[(train[hero] == 1) | (train[hero] == -1)][hero].count()\n",
    "    top_6.loc[top_6[top_6.hero == hero].index, 'total_pick'] = total_pick\n",
    "\n",
    "top_6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a graph for top 6 heros highest picked during the game\n",
    "top_6_highest_pick = top_6.nlargest(6, 'total_pick')\n",
    "\n",
    "df = pd.DataFrame({ 'hero':top_6_highest_pick.hero, 'total_pick':top_6_highest_pick.total_pick})\n",
    "df = df[[\"hero\",\"total_pick\"]]\n",
    "df.set_index([\"hero\"],inplace=True)\n",
    "df.plot(kind='bar',color='g', rot=0, legend=False)\n",
    "plt.show()\n",
    "\n",
    "top_6_highest_pick.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes = list(df.index)\n",
    "counts = list(df.total_pick)\n",
    "\n",
    "source = ColumnDataSource(data=dict(heroes=heroes, counts=counts, color=Spectral6))\n",
    "\n",
    "p = figure(x_range=heroes, plot_height=450, plot_width=750, title=\"Top 6 most pick heroes\")\n",
    "p.vbar(x='heroes', top='counts', width=0.5, color='color', source=source)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a graph for top 5 heros lowest picked during the game\n",
    "top_6_smallest_pick = top_6.nsmallest(6, 'total_pick')\n",
    "\n",
    "df = pd.DataFrame({ 'hero':top_6_smallest_pick.hero, 'total_pick':top_6_smallest_pick.total_pick})\n",
    "df = df[[\"hero\",\"total_pick\"]]\n",
    "df.set_index([\"hero\"],inplace=True)\n",
    "df.plot(kind='bar',color='r', rot=0, legend=False)\n",
    "plt.show()\n",
    "\n",
    "top_6_smallest_pick.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Team won the most\n",
    "teams = pd.DataFrame({'team': ['Radiant','Dire'], 'total_won': 0})\n",
    "\n",
    "teams.loc[teams[teams.team == 'Radiant'].index, 'total_won'] = train[train.team_won == 1].team_won.count()\n",
    "teams.loc[teams[teams.team == 'Dire'].index, 'total_won'] = train[train.team_won == -1].team_won.count()\n",
    "teams.set_index([\"team\"],inplace=True)\n",
    "teams.plot(kind='bar',color='y', rot=0, legend=False)\n",
    "plt.show()\n",
    "\n",
    "teams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing: Feature Engineering\n",
    "\n",
    "Feature Engineering by converting the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['radiant_int'] = 0\n",
    "train['dire_int'] = 0\n",
    "\n",
    "test['radiant_int'] = 0\n",
    "test['dire_int'] = 0\n",
    "\n",
    "train['radiant_str'] = 0\n",
    "train['dire_str'] = 0\n",
    "\n",
    "test['radiant_str'] = 0\n",
    "test['dire_str'] = 0\n",
    "\n",
    "train['radiant_agi'] = 0\n",
    "train['dire_agi'] = 0\n",
    "\n",
    "test['radiant_agi'] = 0\n",
    "test['dire_agi'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sampling train/test data and reduce it to 45%\n",
    "train = train.sample(frac=0.45, random_state=1)\n",
    "test = test.sample(frac=0.45, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Categorize all the heroes selections\n",
    "agis = ['antimage', 'bloodseeker', 'drow_ranger', \n",
    "        'juggernaut', 'mirana', 'nevermore', 'morphling', 'phantom_lancer',\n",
    "        'razor', 'vengefulspirit', 'riki','sniper','venomancer','faceless_void',\n",
    "        'phantom_assassin','templar_assassin','viper','luna','clinkz','broodmother','bounty_hunter','weaver',\n",
    "        'spectre','doom_bringer','ursa','gyrocopter','lone_druid','meepo','undying','nyx_assassin','naga_siren',\n",
    "        'slark','medusa','troll_warlord','terrorblade','unknown_hero']\n",
    "\n",
    "strs = ['axe', 'earthshaker', 'pudge', 'sand_king', \n",
    "        'sven', 'tiny', 'kunkka', 'slardar', 'tidehunter', 'beastmaster', \n",
    "        'skeleton_king', 'dragon_knight', 'rattletrap', 'life_stealer', 'omniknight', 'huskar', 'night_stalker', 'batrider',\n",
    "        'spirit_breaker', 'alchemist', 'lycan', 'brewmaster', 'chaos_knight', 'treant','centaur','magnataur',\n",
    "        'bristleback','shredder', 'tusk', 'abaddon', 'legion_commander', 'elder_titan', 'phoenix']\n",
    "\n",
    "ints = ['crystal_maiden', 'bane', 'puck', 'storm_spirit', \n",
    "        'windrunner', 'zeus', 'lina', 'lich', 'lion', 'shadow_shaman', \n",
    "        'witch_doctor', 'enigma', 'tinker', 'necrolyte', 'warlock', 'queenofpain', \n",
    "        'death_prophet', 'pugna', 'dazzle', 'leshrac', 'furion', 'dark_seer', 'enchantress', 'jakiro', \n",
    "        'chen', 'ancient_apparition', 'invoker', 'silencer', 'obsidian_destroyer', 'shadow_demon', 'rubick', 'disruptor',\n",
    "        'keeper_of_the_light', 'wisp','visage','skywrath_mage','ember_spirit','earth_spirit',\n",
    "        'abyssal_underlord','winter_wyvern','ogre_magi','techies', 'oracle','arc_warden']\n",
    "\n",
    "def categorize_heroes(data):\n",
    "    for index, row in data.iterrows():\n",
    "        for i in agis:\n",
    "            if(row[i] == 1):\n",
    "                row['radiant_agi'] = row['radiant_agi'] + 1\n",
    "\n",
    "            if(row[i] == -1):\n",
    "                row['dire_agi'] = row['dire_agi'] + 1\n",
    "\n",
    "        for i in strs:\n",
    "            if(row[i] == 1):\n",
    "                row['radiant_str'] = row['radiant_str'] + 1\n",
    "\n",
    "            if(row[i] == -1):\n",
    "                row['dire_str'] = row['dire_str'] + 1\n",
    "\n",
    "        for i in ints:\n",
    "            if(row[i] == 1):\n",
    "                row['radiant_int'] = row['radiant_int'] + 1\n",
    "\n",
    "            if(row[i] == -1):\n",
    "                row['dire_int'] = row['dire_int'] + 1\n",
    "\n",
    "categorize_heroes(train)\n",
    "categorize_heroes(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop(['cluster_id','game_mode','game_type'], axis=1)\n",
    "test = test.drop(['cluster_id','game_mode','game_type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop(['antimage','axe','bane','bloodseeker','crystal_maiden','drow_ranger',\n",
    "           'earthshaker','juggernaut','mirana','nevermore','morphling',\n",
    "           'phantom_lancer','puck','pudge','razor','sand_king',\n",
    "           'storm_spirit','sven','tiny','vengefulspirit',\n",
    "           'windrunner','zeus','kunkka','lina','lich','lion',\n",
    "           'shadow_shaman','slardar','tidehunter','witch_doctor',\n",
    "           'riki','enigma','tinker','sniper','necrolyte','warlock',\n",
    "           'beastmaster','queenofpain','venomancer','faceless_void',\n",
    "           'skeleton_king','death_prophet','phantom_assassin','pugna',\n",
    "           'templar_assassin','viper','luna','dragon_knight','dazzle',\n",
    "           'rattletrap','leshrac','furion','life_stealer','dark_seer',\n",
    "           'clinkz','omniknight','enchantress','huskar','night_stalker',\n",
    "           'broodmother','bounty_hunter','weaver','jakiro','batrider',\n",
    "           'chen','spectre','doom_bringer','ancient_apparition','ursa',\n",
    "           'spirit_breaker','gyrocopter','alchemist','invoker','silencer',\n",
    "           'obsidian_destroyer','lycan','brewmaster','shadow_demon','lone_druid',\n",
    "           'chaos_knight','meepo','treant','ogre_magi','undying','rubick','disruptor',\n",
    "           'nyx_assassin','naga_siren','keeper_of_the_light','wisp','visage','slark',\n",
    "           'medusa','troll_warlord','centaur','magnataur','shredder','bristleback',\n",
    "           'tusk','skywrath_mage','abaddon','elder_titan','legion_commander','ember_spirit',\n",
    "           'earth_spirit','abyssal_underlord','terrorblade','phoenix','techies','oracle',\n",
    "           'winter_wyvern','arc_warden', 'unknown_hero'], axis=1)\n",
    "\n",
    "test = test.drop(['antimage','axe','bane','bloodseeker','crystal_maiden','drow_ranger',\n",
    "           'earthshaker','juggernaut','mirana','nevermore','morphling',\n",
    "           'phantom_lancer','puck','pudge','razor','sand_king',\n",
    "           'storm_spirit','sven','tiny','vengefulspirit',\n",
    "           'windrunner','zeus','kunkka','lina','lich','lion',\n",
    "           'shadow_shaman','slardar','tidehunter','witch_doctor',\n",
    "           'riki','enigma','tinker','sniper','necrolyte','warlock',\n",
    "           'beastmaster','queenofpain','venomancer','faceless_void',\n",
    "           'skeleton_king','death_prophet','phantom_assassin','pugna',\n",
    "           'templar_assassin','viper','luna','dragon_knight','dazzle',\n",
    "           'rattletrap','leshrac','furion','life_stealer','dark_seer',\n",
    "           'clinkz','omniknight','enchantress','huskar','night_stalker',\n",
    "           'broodmother','bounty_hunter','weaver','jakiro','batrider',\n",
    "           'chen','spectre','doom_bringer','ancient_apparition','ursa',\n",
    "           'spirit_breaker','gyrocopter','alchemist','invoker','silencer',\n",
    "           'obsidian_destroyer','lycan','brewmaster','shadow_demon','lone_druid',\n",
    "           'chaos_knight','meepo','treant','ogre_magi','undying','rubick','disruptor',\n",
    "           'nyx_assassin','naga_siren','keeper_of_the_light','wisp','visage','slark',\n",
    "           'medusa','troll_warlord','centaur','magnataur','shredder','bristleback',\n",
    "           'tusk','skywrath_mage','abaddon','elder_titan','legion_commander','ember_spirit',\n",
    "           'earth_spirit','abyssal_underlord','terrorblade','phoenix','techies','oracle',\n",
    "           'winter_wyvern','arc_warden', 'unknown_hero'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape, test.shape)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Null Value\n",
    "print(find_column_null(train))\n",
    "print(find_column_null(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['team_won'], axis=1).values\n",
    "y_train = train['team_won']\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "X_test = test.drop(['team_won'], axis=1).values\n",
    "y_test = test['team_won']\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVM Model\n",
    "svc_rbf = SVC(kernel='rbf', C=5).fit(X_train, y_train)\n",
    "#svc_linear = SVC(kernel='linear', C=5).fit(X_train, y_train)\n",
    "#svc_poly = SVC(kernel='poly', C=5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic Regression Model\n",
    "LGR = LogisticRegression(C=5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "GNB = GaussianNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Random Forest Classifier\n",
    "RFC = RandomForestClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Neural Network MLP Regressor Model\n",
    "mlpclass = MLPClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the highest model accuracy score\n",
    "list_of_models = [\n",
    "    ('Support Vector Machine with RBF', knn),\n",
    "    ('KNeighbors Classifier', knn),\n",
    "    ('Logistic Regression', LGR),\n",
    "    ('Naive Bayes', GNB),\n",
    "    ('Random Forest Classifier', RFC),\n",
    "    ('Neural Network Classified', mlpclass),\n",
    "]\n",
    "\n",
    "calculate_model_scores(list_of_models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit with Ada Boost Classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_model = AdaBoostClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit the Random Forest Classifier using Bagging Classifier\n",
    "bag = BaggingClassifier(RandomForestClassifier()).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Grid Search for Random Forest Classifiers\n",
    "parameters = {\n",
    "    'n_estimators': [200, 700],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "gcv = GridSearchCV(rfc, parameters).fit(X_train, y_train)\n",
    "\n",
    "print_accuracy(gcv, X_train, y_train, 'Grid Search CV', 'training')\n",
    "print_accuracy(gcv, X_train, y_train, 'Grid Search CV', 'test')\n",
    "\n",
    "print(gcv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit all the parameters to RFC\n",
    "RFC_GV = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=200, n_jobs=1, oob_score=False, random_state=None,\n",
    "            verbose=0, warm_start=False).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the highest model accuracy score\n",
    "list_of_models = [\n",
    "    ('Ada Boost Classifier', ada_model),\n",
    "    ('Bagging Classifiers with Random Forest Classifier', bag),\n",
    "    ('Grid Search with Random Forest Classifier', gcv),\n",
    "]\n",
    "\n",
    "calculate_model_scores(list_of_models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare Bagging Random Forest Classifieds with Random Forest Classified\n",
    "list_of_models = [\n",
    "    ('Random Forest Classifier', RFC),\n",
    "    ('Bagging Classifiers with Random Forest Classifier', bag),\n",
    "    ('Random Forest Classifier with fine tune parameters', RFC_GV),\n",
    "]\n",
    "\n",
    "calculate_model_scores(list_of_models, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot confusion matrix using Random Forest Classifieds\n",
    "plot_confusion_matrix(X_test, y_test, RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot confusion matrix using Bagging Random Forest Classifieds\n",
    "plot_confusion_matrix(X_test, y_test, bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your models with test values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test your models with random values\n",
    "data = pd.DataFrame({ \n",
    "'radiant_int': [3],\n",
    "'dire_int': [2],\n",
    "'radiant_str': [1],\n",
    "'dire_str': [2],\n",
    "'radiant_agi': [1],\n",
    "'dire_agi': [1]})\n",
    "\n",
    "prediction = RFC.predict(data)\n",
    "prediction_prob = RFC.predict_proba(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction[0])\n",
    "\n",
    "arr = np.array(prediction_prob)\n",
    "print('Radiant with percentage: ',arr[0,1])\n",
    "print('Dire with percentage: ',arr[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "from IPython.html import widgets\n",
    "from IPython.html.widgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_model(model):\n",
    "    if(model == '0'):\n",
    "        model = RFC\n",
    "    elif(model == '1'):\n",
    "        model = bag\n",
    "    elif(model == '3'):\n",
    "        model = GNB\n",
    "    elif(model == '4'):\n",
    "        model = knn\n",
    "    elif(model == '5'):\n",
    "        model = mlpclass\n",
    "    else:\n",
    "        model = RFC\n",
    "    return model\n",
    "\n",
    "def create_plot(selected_model, rad_int, rad_str, rad_agi, dire_int, dire_str, dire_agi):\n",
    "    \n",
    "    print_line()\n",
    "    \n",
    "    total_rad = rad_int + rad_str + rad_agi\n",
    "    total_dire = dire_int + dire_str + dire_agi\n",
    "    \n",
    "    if(total_rad != 5):\n",
    "        print('Error: Radiant team must be exactly 5 heroes')\n",
    "    \n",
    "    elif(total_dire != 5):\n",
    "        print('Error: Dire team must be exactly 5 heroes')\n",
    "    \n",
    "    else:\n",
    "        data = pd.DataFrame({ \n",
    "        'radiant_int': [rad_int],\n",
    "        'dire_int': [dire_int],\n",
    "        'radiant_str': [rad_str],\n",
    "        'dire_str': [dire_str],\n",
    "        'radiant_agi': [rad_agi],\n",
    "        'dire_agi': [dire_agi]})\n",
    "        \n",
    "        model = select_model(selected_model)\n",
    "        \n",
    "        prediction = model.predict(data)\n",
    "        prediction_prob = model.predict_proba(data)\n",
    "\n",
    "        if(prediction[0] == 1):\n",
    "            team = 'Radiant'\n",
    "        else:\n",
    "            team = 'Dire'\n",
    "\n",
    "        arr = np.array(prediction_prob)\n",
    "\n",
    "        RADIANT_PERCENTAGE = round(float(arr[0,1]) * 100)\n",
    "        DIRE_PERCENTAGE = 100 - RADIANT_PERCENTAGE\n",
    "        \n",
    "        print('Radiant: ', RADIANT_PERCENTAGE, '%.', 'Dire: ', DIRE_PERCENTAGE, '%.', team, 'will win')\n",
    "        \n",
    "        teams = ['Radiant', 'Dire']\n",
    "        \n",
    "        p = figure(x_range=teams, \n",
    "                   y_axis_label = 'Percentage (%)',\n",
    "                   plot_height=350, \n",
    "                   title=\"Probability of team to win\")\n",
    "        p.vbar(x=teams, top=[RADIANT_PERCENTAGE, DIRE_PERCENTAGE], \n",
    "               width=0.5, \n",
    "               color=['#d53e4f','#fee08b'])\n",
    "        p.xgrid.grid_line_color = None\n",
    "        p.y_range.start = 0\n",
    "        show(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slider_rad_int = widgets.IntSlider(value=1,min=0,max=5,step=1,description='Radiant Int:')\n",
    "slider_rad_str = widgets.IntSlider(value=2,min=0,max=5,step=1,description='Radiant Str:')\n",
    "slider_rad_agi = widgets.IntSlider(value=2,min=0,max=5,step=1,description='Radiant Agi:')\n",
    "slider_dire_int = widgets.IntSlider(value=1,min=0,max=5,step=1,description='Dire Int:')\n",
    "slider_dire_str = widgets.IntSlider(value=2,min=0,max=5,step=1,description='Dire Str:')\n",
    "slider_dire_agi = widgets.IntSlider(value=2,min=0,max=5,step=1,description='Dire Agi:')\n",
    "\n",
    "choose_task = widgets.Dropdown(\n",
    "    options={'Random Forest Classifier': '0', \n",
    "             'Bagging with Random Classifier': '1', \n",
    "             'Naive Bayes': '3',\n",
    "             'KNN' : '4',\n",
    "             'Neural Network Classified' : '5'\n",
    "            },\n",
    "    value='0',\n",
    "    description='Model Selection:',\n",
    ")\n",
    "\n",
    "interactive_plot = interactive(create_plot, selected_model=choose_task,\n",
    "                               rad_int=slider_rad_int, rad_str=slider_rad_str, rad_agi=slider_rad_agi,\n",
    "                               dire_int=slider_dire_int, dire_str=slider_dire_str, dire_agi=slider_dire_agi,\n",
    "                              )\n",
    "\n",
    "\n",
    "output = interactive_plot.children[-1]\n",
    "output.layout.height = '700px'\n",
    "output.layout.width = '800px'\n",
    "\n",
    "interactive_plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
